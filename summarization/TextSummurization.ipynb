{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from string import punctuation\n",
    "from heapq import nlargest\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import math\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "summurizer = pipeline('summarization', framework='pt')\n",
    "stop_words = list(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "from docx.shared import Inches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacytextblob.spacytextblob.SpacyTextBlob at 0x2df020c70>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "# The polarity score is a float within the range [-1.0, 1.0]. The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective. \n",
    "nlp.add_pipe('spacytextblob')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Paragraph:\n",
    "\n",
    "    def __init__(self, content, heading, heading_style, corpus):\n",
    "        self.content = content\n",
    "        self.heading = heading\n",
    "        self.heading_style = heading_style\n",
    "        self.corpus = corpus\n",
    "        self.summary = self.summarize(ratio=0.5)\n",
    "        self.polarity = self.get_polarity()\n",
    "        self.subjectivity = self.get_subjectivity()\n",
    "\n",
    "    def get_keywords(self, **kwargs):\n",
    "        doc = nlp(self.content)\n",
    "        tags = ['PROPN', 'NOUN'] # alternative ['PROPN', 'ADJ', 'NOUN']\n",
    "        keywords = {}\n",
    "\n",
    "        for token in doc:\n",
    "             if token.pos_ in tags and token.lemma_ not in punctuation:\n",
    "                tf_idf = self.get_tf_idf(token.lemma_)\n",
    "                if token.lemma_ not in keywords.keys():\n",
    "                    keywords[token.lemma_] = tf_idf\n",
    "        \n",
    "        return sorted(keywords, key=keywords.get)[:kwargs.get('n')]\n",
    "    \n",
    "    def summarize(self, **kwargs):\n",
    "\n",
    "        if kwargs.get('strategy') == 'abstract':\n",
    "            try:\n",
    "                return summurizer(self.content, min_length=100, max_length= 200)[0]['summary_text']\n",
    "            except:\n",
    "                return self.summary\n",
    "\n",
    "        doc = nlp(self.content)\n",
    "\n",
    "        # Create dictionary with tokens as keys and their frequency as the value\n",
    "        token_frequencies = {}\n",
    "        for token in doc:\n",
    "            if token.text not in stop_words:\n",
    "                if token.text not in token_frequencies.keys():\n",
    "                    token_frequencies[token.text] = 1\n",
    "                else:\n",
    "                    token_frequencies[token.text] += 1\n",
    "        \n",
    "        # Divide each token by the maximum frequency to get the waited frequency of each token\n",
    "        for token in token_frequencies:\n",
    "            token_frequencies[token] = token_frequencies[token] / max(token_frequencies.values())\n",
    "\n",
    "        # Create dictionary with sentence as key and scentence score as value\n",
    "        scentence_list = [s for s in doc.sents]\n",
    "        scentence_score = {}\n",
    "\n",
    "        # sentence score is equal to sum of token scores for each token in the scentence\n",
    "        for sentence in scentence_list:\n",
    "            for token in sentence:\n",
    "                if token.text.lower() in token_frequencies.keys():\n",
    "                    if len(sentence.text.split(' ')) < 30:\n",
    "                        if sentence not in scentence_score.keys():\n",
    "                            scentence_score[sentence] = token_frequencies[token.text.lower()]\n",
    "                        else:\n",
    "                            scentence_score[sentence] += token_frequencies[token.text.lower()]\n",
    "\n",
    "        # Summurize documents to n-sentences\n",
    "        n = math.floor(kwargs.get('ratio') * len(scentence_list))\n",
    "\n",
    "        summurized_sentences = nlargest(n, scentence_score, key=scentence_score.get)\n",
    "        summary = [s for s in scentence_score.keys() if s in summurized_sentences]\n",
    "        new_text = ' '.join([s.text for s in summary])\n",
    "        \n",
    "        #print(len(self.content), '-', len(new_text),'=',f'{len(self.content) - len(new_text)} words saved')\n",
    "\n",
    "        return new_text\n",
    "    \n",
    "    # a float within the range [-1.0, 1.0].\n",
    "    def get_polarity(self):\n",
    "        polarity_num = nlp(self.content)._.polarity\n",
    "        polarity_txt = ''\n",
    "        \n",
    "        if polarity_num >= 0.6:\n",
    "            polarity_txt = 'Very Positive'\n",
    "        elif polarity_num >= 0.2:\n",
    "            polarity_txt = 'Positive'\n",
    "        elif polarity_num >= -0.2:\n",
    "            polarity_txt = 'Neutral'\n",
    "        elif polarity_num >= -0.6:\n",
    "            polarity_txt = 'Negative'\n",
    "        elif polarity_num < -0.6:\n",
    "            polarity_txt = 'Very Negative'\n",
    "\n",
    "        return (polarity_txt, polarity_num)\n",
    "    # a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective. \n",
    "    def get_subjectivity(self):\n",
    "        return nlp(self.content)._.subjectivity\n",
    "\n",
    "    def get_tf_idf(self, token):\n",
    "        count_tf = 0\n",
    "        ### TF\n",
    "        for word in nlp(self.content):\n",
    "            if word.text == token:\n",
    "                count_tf += 1\n",
    "\n",
    "        tf = count_tf/len(self.content.split())\n",
    "\n",
    "        ### IDF\n",
    "        n_documents = len(self.corpus)\n",
    "        count_idf = 0\n",
    "        for paragraph in self.corpus:\n",
    "            if token in paragraph.text:\n",
    "                count_idf += 1\n",
    "        \n",
    "        idf = math.log(n_documents / count_idf, 2) if count_idf != 0 else 0\n",
    "\n",
    "        return tf * idf   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bachelor_thesis = Document('./../Lukas-Linss_ba.docx')\n",
    "paragraphs = bachelor_thesis.paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_objs = list()\n",
    "for i, p in enumerate(paragraphs):\n",
    "    if len(p.text) > 100:\n",
    "        paragraph_objs.append(Paragraph(p.text, paragraphs[i - 1].text, int(paragraphs[i - 1].style.name[-1]), paragraphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = Document()\n",
    "title = document.add_heading(bachelor_thesis.core_properties.title, 0)\n",
    "title.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "document.add_page_break()\n",
    "\n",
    "for p in paragraph_objs:\n",
    "    document.add_heading(p.heading, p.heading_style)\n",
    "    paragraph = document.add_paragraph(p.summarize(ratio=0.5)) # p.summarize(strategy='abstract') fuer die abstrakte Methode\n",
    "    paragraph.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY\n",
    "    document.add_paragraph(f'Keywords: { p.get_keywords(n=4) }')\n",
    "    document.add_paragraph(f'Polarity: {p.polarity[0]} ({round(p.polarity[1], 2)})')\n",
    "    document.add_paragraph(f'Subjectivity: {round(p.subjectivity, 2)} / 1.0')\n",
    "\n",
    "    document.add_page_break()\n",
    "\n",
    "document.save(f'ba summary {bachelor_thesis.core_properties.author}.docx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
